redox15mins_unique$Date <- gsub( " .*$", "", redox15mins_unique$TIMESTAMP) # as character
redox15mins_unique$Date2 <- mdy(redox15mins_unique$Date) # as date
# average by hour?
## convert to long format
redox15minslong <- gather(redox15mins_unique, SensorID, SEVolt,
c(SensorV1:SensorV4,SensorR1:SensorR8))
redox15minslong$SensorID <- as.character(redox15minslong$SensorID)
redox15minslong$SEVolt <- as.numeric(redox15minslong$SEVolt)
## get daily mean, sd, max, min
redoxdailylong <- ddply(redox15minslong,.(Date2, SensorID),
summarize,
avgSEVolt=mean(SEVolt, strna.rm = TRUE),
sdSEVolt=sd(SEVolt, na.rm = TRUE),
seSEVolt=sqrt(var(SEVolt,na.rm=TRUE)/length(na.omit(SEVolt))),
maxSEVolt=max(SEVolt, na.rm = TRUE),
minSEVolt=min(SEVolt, na.rm = TRUE),
.progress="text") # na.rm=T already in the function definition for ste()
# hourly wide for each
head(vwchourly)
head(temphourly)
head(O2hourly) # this is mV, not %
head(redox15mins_unique)
# daily wide for each
# go from long to wide using spread() from tidyr
# only do this for the average daily values, not the sd, se, min or max
vwcdailylongavg <- vwcdailylong[,c(1:3)]
vwcdailywideavg <- spread(vwcdailylongavg, SensorID, avgVWC)
tempdailylongavg <- tempdailylong[,c(1:3)]
tempdailywideavg <- spread(tempdailylongavg, SensorID, avgTemp)
O2dailylongavg <- O2dailylong[,c(1:3)]
O2dailywideavg <- spread(O2dailylongavg, SensorID, avgO2pct)
redoxdailylongavg <- redoxdailylong[,1:3]
redoxdailywideavg <- spread(redoxdailylongavg,SensorID, avgSEVolt)
head(tempdailywideavg)
head(vwcdailywideavg)
head(O2dailywideavg)
head(redoxdailywideavg)
# daily long combined dataset
head(fulldaily)
########################################################################
# SAVE AS CSVS
# hourly wide for each
# make ok to write to CSV
vwchourly$TIMESTAMP2 <- as.character(vwchourly$TIMESTAMP2)
vwchourly$Date2 <- as.character(vwchourly$Date2)
temphourly$TIMESTAMP2 <- as.character(temphourly$TIMESTAMP2)
temphourly$Date2 <- as.character(temphourly$Date2)
O2hourlylong$TIMESTAMP2 <- as.character(O2hourlylong$TIMESTAMP2)
O2hourlylong$Date2 <- as.character(O2hourlylong$Date2)
redox15mins_unique$TIMESTAMP2 <- as.character(redox15mins_unique$TIMESTAMP2)
redox15mins_unique$Date2 <- as.character(redox15mins_unique$Date2)
# write to csv
write.csv(vwchourly, file=paste(outputdatapath, "vwchourly.csv", sep = ""), row.names=FALSE)
write.csv(temphourly, file=paste(outputdatapath, "temphourly.csv", sep = ""), row.names=FALSE)
write.csv(O2hourlylong, file=paste(outputdatapath, "O2hourly.csv", sep = ""), row.names=FALSE)
write.csv(redox15mins_unique, file=paste(outputdatapath, "redox15mins.csv", sep= ""), row.names=FALSE)
vwcdailywideavg$Date2 <- as.character(vwcdailywideavg$Date2)
tempdailywideavg$Date2 <- as.character(tempdailywideavg$Date2)
O2dailywideavg$Date2 <- as.character(O2dailywideavg$Date2)
redoxdailywideavg$Date2 <- as.character(redoxdailywideavg$Date2)
# write to csv
write.csv(redoxdailywideavg, file=paste(outputdatapath, "redoxdailywideavg.csv", sep =""), row.names=FALSE)
str(fulldaily)
ggplot(redoxdailylong,aes(x=as.Date(Date2),y=avgSEVolt))+
geom_point() +
labs(x="Date",y="SEVolt")
## get data from "r"
redoxRcols <- c(1,3,7,11,15,19,23,27,31)
dataend <- dim(CR1000_redoxR)[1]
redoxrows <- c(4:dataend)
redoxRnames <- c("TIMESTAMP","SensorR1","SensorR2","SensorR3","SensorR4",
"SensorR5","SensorR6","SensorR7","SensorR8")
# extract the data and give it useful col names
redoxR15mins <- CR1000_redoxR[redoxrows, redoxRcols]
names(redoxR15mins) <- redoxRnames
redoxR15mins$logger <- "R"
## get data from "v"
redoxVcols <- c(1,3,7,11,15)
dataend <- dim(CR1000_redoxV)[1]
redoxrows <- c(4:dataend)
redoxVnames <- c("TIMESTAMP","SensorV1","SensorV2","SensorV3","SensorV4")
# extract the data and give it useful col names
redoxV15mins <- CR1000_redoxV[redoxrows, redoxVcols]
names(redoxV15mins) <- redoxVnames
redoxV15mins$logger <- "V"
## bind T1 and T2 in wide format, make useful columns
redox15mins <- full_join(redoxR15mins, redoxV15mins, by="TIMESTAMP")
redox15mins_unique <- unique(redox15mins) # removes perfect duplicate rows-not sure why these exist?
# replace 7999 values with NA
redox15mins_unique[redox15mins_unique==7999] <- NA
## because the datalogger uses 7999 for NA data - not sure if this is true/needed for redox files?
# make separate columns for date and time
redox15mins_unique$TIMESTAMP2 <- parse_date_time(redox15mins_unique$TIMESTAMP, orders="mdy HM") # as date
# get hour
redox15mins_unique$Hour <- gsub( ".* ", "", redox15mins_unique$TIMESTAMP) # as character
redox15mins_unique$Hour2 <- hour(redox15mins_unique$TIMESTAMP2) # as int
# get date
redox15mins_unique$Date <- gsub( " .*$", "", redox15mins_unique$TIMESTAMP) # as character
redox15mins_unique$Date2 <- mdy(redox15mins_unique$Date) # as date
# average by hour?
## convert to long format
redox15minslong <- gather(redox15mins_unique, SensorID, SEVolt,
c(SensorV1:SensorV4,SensorR1:SensorR8))
redox15minslong$SensorID <- as.character(redox15minslong$SensorID)
redox15minslong$SEVolt <- as.numeric(redox15minslong$SEVolt)
## get daily mean, sd, max, min
redoxdailylong <- ddply(redox15minslong,.(Date2, SensorID),
summarize,
avgSEVolt=mean(SEVolt, strna.rm = TRUE),
sdSEVolt=sd(SEVolt, na.rm = TRUE),
seSEVolt=sqrt(var(SEVolt,na.rm=TRUE)/length(na.omit(SEVolt))),
maxSEVolt=max(SEVolt, na.rm = TRUE),
minSEVolt=min(SEVolt, na.rm = TRUE),
.progress="text") # na.rm=T already in the function definition for ste()
ggplot(redoxdailylong,aes(x=as.Date(Date2),y=avgSEVolt,color=logger))+
geom_point() +
labs(x="Date",y="SEVolt")
str(redoxdailylong)
str(redox15minslong)
View(redox15minslong)
View(redox15mins)
# extract the data and give it useful col names
redoxR15mins <- CR1000_redoxR[redoxrows, redoxRcols]
names(redoxR15mins) <- redoxRnames
## get data from "v"
redoxVcols <- c(1,3,7,11,15)
dataend <- dim(CR1000_redoxV)[1]
redoxrows <- c(4:dataend)
redoxVnames <- c("TIMESTAMP","SensorV1","SensorV2","SensorV3","SensorV4")
# extract the data and give it useful col names
redoxV15mins <- CR1000_redoxV[redoxrows, redoxVcols]
names(redoxV15mins) <- redoxVnames
## bind T1 and T2 in wide format, make useful columns
redox15mins <- full_join(redoxR15mins, redoxV15mins, by="TIMESTAMP")
redox15mins_unique <- unique(redox15mins) # removes perfect duplicate rows-not sure why these exist?
?full_join
definetransects <- read.csv(paste(calibrationdatapath,"definetransects.csv",sep=""), stringsAsFactors=FALSE)
str(definetransects)
definelogger <- data.frame(SensorID = c("SensorV1","SensorV2","SensorV3","SensorV4",
"SensorR1","SensorR2","SensorR3","SensorR4",
"SensorR5","SensorR6","SensorR7","SensorR8"),
LoggerID = c("V","V","V","V","R","R","R","R","R","R","R","R")
)
redox15minslong <- gather(redox15mins_unique, SensorID, SEVolt,
c(SensorV1:SensorV4,SensorR1:SensorR8))
redox15minslong$SensorID <- as.character(redox15minslong$SensorID)
redox15minslong$SEVolt <- as.numeric(redox15minslong$SEVolt)
# add column for datalogger/topolocation placeholder
definelogger <- data.frame(SensorID = c("SensorV1","SensorV2","SensorV3","SensorV4",
"SensorR1","SensorR2","SensorR3","SensorR4",
"SensorR5","SensorR6","SensorR7","SensorR8"),
LoggerID = c("V","V","V","V","R","R","R","R","R","R","R","R")
)
redox15minslong <- full_join(redox15minslong, definelogger)
str(redox15minslong)
redox15minslong <- gather(redox15mins_unique, SensorID, SEVolt,
c(SensorV1:SensorV4,SensorR1:SensorR8))
redox15minslong$SensorID <- as.character(redox15minslong$SensorID)
redox15minslong$SEVolt <- as.numeric(redox15minslong$SEVolt)
# add column for datalogger/topolocation placeholder
definelogger <- data.frame(SensorID = c("SensorV1","SensorV2","SensorV3","SensorV4",
"SensorR1","SensorR2","SensorR3","SensorR4",
"SensorR5","SensorR6","SensorR7","SensorR8"),
LoggerID = as.factor(c("V","V","V","V","R","R","R","R","R","R","R","R"))
)
redox15minslong <- full_join(redox15minslong, definelogger)
redox15minslong <- gather(redox15mins_unique, SensorID, SEVolt,
c(SensorV1:SensorV4,SensorR1:SensorR8))
redox15minslong$SensorID <- as.character(redox15minslong$SensorID)
redox15minslong$SEVolt <- as.numeric(redox15minslong$SEVolt)
str(redox15minslong)
# add column for datalogger/topolocation placeholder
definelogger <- data.frame(SensorID = c("SensorV1","SensorV2","SensorV3","SensorV4",
"SensorR1","SensorR2","SensorR3","SensorR4",
"SensorR5","SensorR6","SensorR7","SensorR8"),
LoggerID = as.factor(c("V","V","V","V","R","R","R","R","R","R","R","R"))
)
redox15minslong <- full_join(redox15minslong, definelogger)
## get daily mean, sd, max, min
redoxdailylong <- ddply(redox15minslong,.(Date2, SensorID),
summarize,
avgSEVolt=mean(SEVolt, strna.rm = TRUE),
sdSEVolt=sd(SEVolt, na.rm = TRUE),
seSEVolt=sqrt(var(SEVolt,na.rm=TRUE)/length(na.omit(SEVolt))),
maxSEVolt=max(SEVolt, na.rm = TRUE),
minSEVolt=min(SEVolt, na.rm = TRUE),
.progress="text") # na.rm=T already in the function definition for ste()
## get data from "r"
redoxRcols <- c(1,3,7,11,15,19,23,27,31)
dataend <- dim(CR1000_redoxR)[1]
redoxrows <- c(4:dataend)
redoxRnames <- c("TIMESTAMP","SensorR1","SensorR2","SensorR3","SensorR4",
"SensorR5","SensorR6","SensorR7","SensorR8")
# extract the data and give it useful col names
redoxR15mins <- CR1000_redoxR[redoxrows, redoxRcols]
names(redoxR15mins) <- redoxRnames
## get data from "v"
redoxVcols <- c(1,3,7,11,15)
dataend <- dim(CR1000_redoxV)[1]
redoxrows <- c(4:dataend)
redoxVnames <- c("TIMESTAMP","SensorV1","SensorV2","SensorV3","SensorV4")
# extract the data and give it useful col names
redoxV15mins <- CR1000_redoxV[redoxrows, redoxVcols]
names(redoxV15mins) <- redoxVnames
## bind T1 and T2 in wide format, make useful columns
redox15mins <- full_join(redoxR15mins, redoxV15mins, by="TIMESTAMP")
redox15mins_unique <- unique(redox15mins) # removes perfect duplicate rows-not sure why these exist?
# replace 7999 values with NA
redox15mins_unique[redox15mins_unique==7999] <- NA
## because the datalogger uses 7999 for NA data - not sure if this is true/needed for redox files?
# make separate columns for date and time
redox15mins_unique$TIMESTAMP2 <- parse_date_time(redox15mins_unique$TIMESTAMP, orders="mdy HM") # as date
# get hour
redox15mins_unique$Hour <- gsub( ".* ", "", redox15mins_unique$TIMESTAMP) # as character
redox15mins_unique$Hour2 <- hour(redox15mins_unique$TIMESTAMP2) # as int
# get date
redox15mins_unique$Date <- gsub( " .*$", "", redox15mins_unique$TIMESTAMP) # as character
redox15mins_unique$Date2 <- mdy(redox15mins_unique$Date) # as date
# average by hour?
## convert to long format
redox15minslong <- gather(redox15mins_unique, SensorID, SEVolt,
c(SensorV1:SensorV4,SensorR1:SensorR8))
redox15minslong$SensorID <- as.character(redox15minslong$SensorID)
redox15minslong$SEVolt <- as.numeric(redox15minslong$SEVolt)
# add column for datalogger/topolocation placeholder
definelogger <- data.frame(SensorID = c("SensorV1","SensorV2","SensorV3","SensorV4",
"SensorR1","SensorR2","SensorR3","SensorR4",
"SensorR5","SensorR6","SensorR7","SensorR8"),
LoggerID = as.factor(c("V","V","V","V","R","R","R","R","R","R","R","R"))
)
redox15minslong <- full_join(redox15minslong, definelogger)
str(redox15minslong)
## get daily mean, sd, max, min
redoxdailylong <- ddply(redox15minslong,.(Date2, SensorID),
summarize,
avgSEVolt=mean(SEVolt, strna.rm = TRUE),
sdSEVolt=sd(SEVolt, na.rm = TRUE),
seSEVolt=sqrt(var(SEVolt,na.rm=TRUE)/length(na.omit(SEVolt))),
maxSEVolt=max(SEVolt, na.rm = TRUE),
minSEVolt=min(SEVolt, na.rm = TRUE),
.progress="text") # na.rm=T already in the function definition for ste()
ggplot(redoxdailylong,aes(x=as.Date(Date2),y=avgSEVolt,color=LoggerID))+
geom_point() +
labs(x="Date",y="SEVolt")
str(redoxdailylong)
length(redoxdailylong)
length(redoxdailylong[,1])
redoxdailylong <- ddply(redox15minslong,.(Date2, SensorID, LoggerID),
summarize,
avgSEVolt=mean(SEVolt, strna.rm = TRUE),
sdSEVolt=sd(SEVolt, na.rm = TRUE),
seSEVolt=sqrt(var(SEVolt,na.rm=TRUE)/length(na.omit(SEVolt))),
maxSEVolt=max(SEVolt, na.rm = TRUE),
minSEVolt=min(SEVolt, na.rm = TRUE),
.progress="text") # na.rm=T already in the function definition for ste()
length(redoxdailylong[,1])
ggplot(redoxdailylong,aes(x=as.Date(Date2),y=avgSEVolt,color=LoggerID))+
geom_point() +
labs(x="Date",y="SEVolt")
ggsave("Redox.jpg",path=outputdatapath)
# Code to analyze O2, temperaturea and moisture results from soil depth arrays
## Based on Process-arraysensorsdf-Sensor-Data-RCode
# packages
library(plyr)
library(dplyr)
library(tidyr)
library(data.table)
library(chron)
library(lubridate)
library(ggplot2)
# define standard error function
ste <- function(x) sqrt(var(x,na.rm=TRUE)/length(na.omit(x)))
# where to save outputs
sensordatapath = "~/Desktop/Datalogger_downloads/4-25-17/"
calibrationdatapath = "~/Desktop/Datalogger_downloads/Calibration files/"
outputdatapath = "~/Desktop/Datalogger_downloads/4-25-17/Depth results/"
########################################################################
# BRING IN NEW DATA SHEETS
# what are the new temperature/moisture/O2 csv files to bring in?
CR1000_DepthTM <- read.csv(paste(sensordatapath,"CR1000_DatoutCS655.csv",sep=""),
stringsAsFactors=FALSE)
CR1000_oxygenEV <- read.csv(paste(sensordatapath,"CR1000_oxygenEVJune2015.csv",
sep=""), stringsAsFactors=FALSE)
# where is the VWC data?
vwccols <- c(1,3,9,15,21,27,33,39,45,51,57,63,69,75,81,219,221,223,225)
dataend <- dim(CR1000_DepthTM)[1]
vwcrows <- c(4:dataend)
# what are the variable names?
vwcnamesDepth <- c("TIMESTAMP","VWC1","VWC2","VWC3","VWC4","VWC5",
"VWC6","VWC7","VWC8","VWC9","VWC10","VWC11",
"VWC12","VWC13","VWC14","VWC15",
"VWC16","VWC17","VWC18") # these are arbitrary numbers, need to rename
# extract the data and give it useful col names
vwchourlyDepth <- CR1000_DepthTM[vwcrows, vwccols]
names(vwchourlyDepth) <- vwcnamesDepth
# replace 7999 values with NA
vwchourlyDepth[vwchourlyDepth==7999] <- NA
## because the datalogger uses 7999 for NA data
# make separate columns for date and time
vwchourlyDepth$TIMESTAMP2 <- parse_date_time(vwchourlyDepth$TIMESTAMP, orders="mdy HM") # as date
# get hour
vwchourlyDepth$Hour <- gsub( ".* ", "", vwchourlyDepth$TIMESTAMP) # as character
vwchourlyDepth$Hour2 <- hour(vwchourlyDepth$TIMESTAMP2) # as int
# get date
vwchourlyDepth$Date <- gsub( " .*$", "", vwchourlyDepth$TIMESTAMP) # as character
vwchourlyDepth$Date2 <- mdy(vwchourlyDepth$Date) # as date
## convert to long format
vwchourlylong <- gather(vwchourlyDepth, SensorID, VWC, VWC1:VWC18)
vwchourlylong$SensorID <- as.character(vwchourlylong$SensorID)
vwchourlylong$VWC <- as.numeric(vwchourlylong$VWC)
## add real sensor IDs
VWCIDs <- read.csv(paste(calibrationdatapath,"VWCIDmatching.csv",
sep=""), stringsAsFactors=FALSE)
vwchourlylongcor <- full_join(vwchourlylong,VWCIDs)
## get daily mean, sd, max, min
vwcdailylong <- ddply(vwchourlylongcor,.(Date2, SensorID,
RealID, TopoLocation,Depth),
summarize,
avgVWC=mean(VWC, na.rm = TRUE),
sdVWC=sd(VWC, na.rm = TRUE),
seVWC=ste(VWC),
maxVWC=max(VWC, na.rm = TRUE),
minVWC=min(VWC, na.rm = TRUE)) # na.rm=T already in the function definition for ste()
## get Depth data
# where is the temp data?
tempcols <- c(1,5,11,17,23,29,35,41,47,53,59,65,71,77,83) #no temp data from C616?
#vwccols  <- c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33)
dataend <- dim(CR1000_DepthTM)[1]
temprows <- c(4:dataend)
# what are the variable names?
tempnamesDepth <- c("TIMESTAMP","VWC1","VWC2","VWC3","VWC4","VWC5",
"VWC6","VWC7","VWC8","VWC9","VWC10",
"VWC11","VWC12","VWC13","VWC14") #again arbitrary but should match the VWC data
# extract the data and give it useful col names
temphourlyDepth <- CR1000_DepthTM[temprows, tempcols]
names(temphourlyDepth) <- tempnamesDepth
# replace 7999 values with NA
temphourlyDepth[temphourlyDepth==7999] <- NA
# make separate columns for date and time
temphourlyDepth$TIMESTAMP2 <- parse_date_time(temphourlyDepth$TIMESTAMP, orders="mdy HM") # as date
# get hour
temphourlyDepth$Hour <- gsub( ".* ", "", temphourlyDepth$TIMESTAMP) # as character
temphourlyDepth$Hour2 <- hour(temphourlyDepth$TIMESTAMP2) # as int
# get date
temphourlyDepth$Date <- gsub( " .*$", "", temphourlyDepth$TIMESTAMP) # as character
temphourlyDepth$Date2 <- mdy(temphourlyDepth$Date) # as date
## convert to long format
temphourlylong <- gather(temphourlyDepth, SensorID, Temp, VWC1:VWC14)
temphourlylong$SensorID <- as.character(temphourlylong$SensorID)
temphourlylong$Temp <- as.numeric(temphourlylong$Temp)
# add real IDs
temphourlylongcor <- full_join(temphourlylong,VWCIDs)
## get daily mean, sd, max, min
tempdailylong <- ddply(temphourlylongcor,.(Date2, SensorID,
RealID, TopoLocation,Depth),
summarize,
avgTemp=mean(Temp, na.rm = TRUE),
sdTemp=sd(Temp, na.rm = TRUE),
seTemp=ste(Temp),
smaxTemp=max(Temp, na.rm = TRUE),
minTemp=min(Temp, na.rm = TRUE)) # na.rm=T already in the function definition for ste()
View(CR1000_oxygenEV)
str(CR1000_oxygenEV)
str(CR1000_oxygenEV[331:345])
str(CR1000_oxygenEV[331:346])
str(CR1000_oxygenEV[c(331:346, 272:273])
str(CR1000_oxygenEV[c(331:346, 272:273)])
O2cols <- c(1,331:346,272:273)
dataend <- dim(CR1000_oxygenEV)[1]
O2rows <- c(4:dataend)
O2names <- c("TIMESTAMP",
"Ox01","Ox02","Ox03","Ox04","Ox05","Ox06",
"Ox07","Ox08","Ox09","Ox10","Ox11","Ox12",
"Ox13","Ox14","Ox15","Ox16","Ox17","Ox18")
O2hourly <- CR1000_oxygenEV[O2rows, O2cols]
names(O2hourly) <- O2names
str(O2hourly)
# replace 7999 values with NA
O2hourly[O2hourly==7999] <- NA
# make separate columns for date and time
O2hourly$TIMESTAMP2 <- parse_date_time(O2hourly$TIMESTAMP, orders="mdy HM") # as date
# get hour
O2hourly$Hour <- gsub( ".* ", "", O2hourly$TIMESTAMP) # as character
O2hourly$Hour2 <- hour(O2hourly$TIMESTAMP2) # as int
# get date
O2hourly$Date <- gsub( " .*$", "", O2hourly$TIMESTAMP) # as character
O2hourly$Date2 <- mdy(O2hourly$Date) # as date
O2hourlylong <- gather(O2hourly, SensorID, O2mV, Ox01:Ox15)
O2hourlylong$SensorID <- as.character(O2hourlylong$SensorID)
O2hourlylong$O2mV <- as.numeric(O2hourlylong$O2mV)
O2hourlylong <- gather(O2hourly, SensorID, O2mV, Ox01:Ox18)
O2hourlylong$SensorID <- as.character(O2hourlylong$SensorID)
O2hourlylong$O2mV <- as.numeric(O2hourlylong$O2mV)
# bring in calibration curve info
O2cal <- read.csv(paste(calibrationdatapath,"O2sensorscalibrationdepth.csv",sep=""), stringsAsFactors=FALSE) #using average of all calibration data
# join to O2hourlylong
O2hourlylong <- full_join(O2hourlylong, O2cal)
# solve for percent O2
O2hourlylong$O2pct <- ((O2hourlylong$O2mV * O2hourlylong$Slope) - O2hourlylong$Intercept) * 100
OxIDs <- read.csv(paste(calibrationdatapath,"OxIDmatching.csv",
sep=""), stringsAsFactors=FALSE)
O2hourlylongcor <- full_join(O2hourlylong,OxIDs)
O2dailylong <- ddply(O2hourlylongcor,.(Date2, SensorID,
RealID, TopoLocation,Depth),
summarize,
avgO2pct=mean(O2pct, na.rm = TRUE),
sdO2pct=sd(O2pct, na.rm = TRUE),
seO2pct=ste(O2pct),
smaxO2pct=max(O2pct, na.rm = TRUE),
minO2pct=min(O2pct, na.rm = TRUE))
# load packages
library(plyr)
library(dplyr)
# locate datasets
DataArchivepath <- "~/Desktop/Datalogger_downloads/DepthDataArchive/"
# old data; this should never change unless changing computers
# christine version; uncomment when CSO doing things
#DataArchivepath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceDataArchive/"
NewDatapath      <- "~/Desktop/Datalogger_downloads/5-9-17/Depth results/"
# this should change each time data is dowloaded
# christine version; uncomment when CSO doing things
#NewDatapath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceNewest/"
# when christine was adding in the very old data
#NewDatapath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceOutOfDate/OldestCSOHas/renamedtomatchcode/"
# create master list of file names
allfiles <- c("fulldaily","O2dailywideavg","O2hourly",
"tempdailywideavg","temphourly",
"vwcdailywideavg","vwchourly")
# bring in old data
OldFiles <- list()
for(i in 1:7) {
OldFiles[[i]] <- as.data.frame(read.csv(paste(DataArchivepath,allfiles[i],".csv",sep=""), stringsAsFactors=FALSE))
names(OldFiles)[i] <- paste("Old",allfiles[i],sep="")
}
# bring in new data
NewFiles <- list()
for(i in 1:7) {
NewFiles[[i]] <- as.data.frame(read.csv(paste(NewDatapath,allfiles[i],".csv",sep=""), stringsAsFactors=FALSE))
names(NewFiles)[i] <- paste("New",allfiles[i],sep="")
}
# Bind datasets
CompleteFiles <- list()
for(i in 1:7) {
stopifnot(names(OldFiles[[i]])==names(NewFiles[[i]]))
CompleteFiles[[i]] <- join(OldFiles[[i]],NewFiles[[i]],type="full")
names(CompleteFiles)[i] <- paste("Complete",allfiles[i],sep="")
}
str(CompleteFiles)
# load packages
library(plyr)
library(dplyr)
# locate datasets
DataArchivepath <- "~/Desktop/Datalogger_downloads/DepthDataArchive/"
# old data; this should never change unless changing computers
# christine version; uncomment when CSO doing things
#DataArchivepath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceDataArchive/"
NewDatapath      <- "~/Desktop/Datalogger_downloads/5-9-17/Depth results/"
# this should change each time data is dowloaded
# christine version; uncomment when CSO doing things
#NewDatapath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceNewest/"
# when christine was adding in the very old data
#NewDatapath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceOutOfDate/OldestCSOHas/renamedtomatchcode/"
# create master list of file names
allfiles <- c("fulldaily","O2dailywideavg","O2hourly",
"tempdailywideavg","temphourly",
"vwcdailywideavg","vwchourly")
# bring in old data
OldFiles <- list()
for(i in 1:7) {
OldFiles[[i]] <- as.data.frame(read.csv(paste(DataArchivepath,allfiles[i],".csv",sep=""), stringsAsFactors=FALSE))
names(OldFiles)[i] <- paste("Old",allfiles[i],sep="")
}
# bring in new data
NewFiles <- list()
for(i in 1:7) {
NewFiles[[i]] <- as.data.frame(read.csv(paste(NewDatapath,allfiles[i],".csv",sep=""), stringsAsFactors=FALSE))
names(NewFiles)[i] <- paste("New",allfiles[i],sep="")
}
# Bind datasets
CompleteFiles <- list()
for(i in 1:7) {
stopifnot(names(OldFiles[[i]])==names(NewFiles[[i]]))
CompleteFiles[[i]] <- join(OldFiles[[i]],NewFiles[[i]],type="full")
names(CompleteFiles)[i] <- paste("Complete",allfiles[i],sep="")
}
# Figures for sanity check
library(ggplot2)
library(lubridate)
fulldaily <- CompleteFiles[[1]]
fulldaily$realDate <- parse_date_time(fulldaily$Date2,orders="ymd")
ggplot(fulldaily,aes(x=realDate,y=avgO2pct,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="O2 concentration")
ggsave("Depth O2.pdf", path = DataArchivepath)
#  scale_y_continuous(limits=c(-2,22)) +
ggplot(fulldaily,aes(x=realDate,y=avgTemp,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="Soil Temp")
ggsave("Depth Soil Temp.pdf", path = DataArchivepath)
ggplot(fulldaily,aes(x=realDate,y=avgVWC,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="Volumetric Water Content")
ggsave("Depth VWC.pdf", path = DataArchivepath)
# Save all data
for(i in 1:7){
write.csv(CompleteFiles[[i]],
file=paste(DataArchivepath,allfiles[i],".csv",sep=""),
row.names=FALSE)
}

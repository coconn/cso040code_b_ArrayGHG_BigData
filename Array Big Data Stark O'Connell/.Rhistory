head(O2hourly)
# daily wide for each
# go from long to wide using spread() from tidyr
# only do this for the average daily values, not the sd, se, min or max
vwcdailylongavg <- vwcdailylong[,c(1:3)]
vwcdailywideavg <- spread(vwcdailylongavg, SensorID, avgVWC)
tempdailylongavg <- tempdailylong[,c(1:3)]
tempdailywideavg <- spread(tempdailylongavg, SensorID, avgTemp)
O2dailylongavg <- O2dailylong[,c(1:3)]
O2dailywideavg <- spread(O2dailylongavg, SensorID, avgO2pct)
head(tempdailywideavg)
head(vwcdailywideavg)
head(O2dailywideavg)
# daily long combined dataset
head(fulldaily)
########################################################################
# SAVE AS CSVS
# hourly wide for each
# make ok to write to CSV
vwchourly$TIMESTAMP2 <- as.character(vwchourly$TIMESTAMP2)
vwchourly$Date2 <- as.character(vwchourly$Date2)
temphourly$TIMESTAMP2 <- as.character(temphourly$TIMESTAMP2)
temphourly$Date2 <- as.character(temphourly$Date2)
O2hourlylong$TIMESTAMP2 <- as.character(O2hourlylong$TIMESTAMP2)
O2hourlylong$Date2 <- as.character(O2hourlylong$Date2)
# write to csv
write.csv(vwchourly, file=paste(outputdatapath, "vwchourly.csv", sep = ""), row.names=FALSE)
write.csv(temphourly, file=paste(outputdatapath, "temphourly.csv", sep = ""), row.names=FALSE)
write.csv(O2hourlylong, file=paste(outputdatapath, "O2hourly.csv", sep = ""), row.names=FALSE)
# daily wide for each
# make ok to write to CSV
vwcdailywideavg$Date2 <- as.character(vwcdailywideavg$Date2)
tempdailywideavg$Date2 <- as.character(tempdailywideavg$Date2)
O2dailywideavg$Date2 <- as.character(O2dailywideavg$Date2)
# write to csv
write.csv(vwcdailywideavg, file=paste(outputdatapath, "vwcdailywideavg.csv", sep = ""), row.names=FALSE)
write.csv(tempdailywideavg, file=paste(outputdatapath, "tempdailywideavg.csv", sep = ""), row.names=FALSE)
write.csv(O2dailywideavg, file=paste(outputdatapath, "O2dailywideavg.csv", sep = ""), row.names=FALSE)
# daily long combined dataset
# make ok to write to CSV
fulldaily$Date2 <- as.character(fulldaily$Date2)
# write to csv
write.csv(fulldaily, file=paste(outputdatapath, "fulldaily.csv", sep = ""), row.names=FALSE)
##### FOR NOW, CHRISTINE IS JUST PASTING THESE INTO THE APPROPRIATE PLACE ON THE RUNNING EXCEL SHEET
ggplot(fulldaily,aes(x=as.Date(Date2),y=avgO2pct,color=TopoLocation)) +
geom_point() +
scale_x_date(limits=as.Date(c("2017-01-01","2017-07-01"))) +
labs(x="Date",y="O2 concentration")
ggsave("SurfaceO2.jpg",path=outputdatapath)
ggplot(fulldaily,aes(x=as.Date(Date2),y=avgTemp,color=TopoLocation)) +
geom_point() +
labs(x="Date",y="Soil Temp")
ggsave("SurfaceTemp.jpg",path=outputdatapath)
ggplot(fulldaily,aes(x=as.Date(Date2),y=avgVWC,color=TopoLocation)) +
geom_point() +
labs(x="Date",y="Volumetric Water Content")
ggsave("SurfaceVWC.jpg",path=outputdatapath)
# Code to analyze O2, temperaturea and moisture results from soil depth arrays
## Based on Process-arraysensorsdf-Sensor-Data-RCode
# packages
library(plyr)
library(dplyr)
library(tidyr)
library(data.table)
library(chron)
library(lubridate)
library(ggplot2)
# define standard error function
ste <- function(x) sqrt(var(x,na.rm=TRUE)/length(na.omit(x)))
# where to save outputs
sensordatapath = "~/Desktop/Datalogger_downloads/4-12-17/"
calibrationdatapath = "~/Desktop/Datalogger_downloads/Calibration files/"
outputdatapath = "~/Desktop/Datalogger_downloads/4-12-17/Depth results/"
########################################################################
# BRING IN NEW DATA SHEETS
# what are the new temperature/moisture/O2 csv files to bring in?
CR1000_DepthTM <- read.csv(paste(sensordatapath,"CR1000_DatoutCS655.csv",sep=""),
stringsAsFactors=FALSE)
CR1000_oxygenEV <- read.csv(paste(sensordatapath,"CR1000_oxygenEVJune2015.csv",
sep=""), stringsAsFactors=FALSE)
# where is the VWC data?
vwccols <- c(1,3,9,15,21,27,33,39,45,51,57,63,69,75,81,219,221,223,225)
dataend <- dim(CR1000_DepthTM)[1]
vwcrows <- c(4:dataend)
# what are the variable names?
vwcnamesDepth <- c("TIMESTAMP","VWC1","VWC2","VWC3","VWC4","VWC5",
"VWC6","VWC7","VWC8","VWC9","VWC10","VWC11",
"VWC12","VWC13","VWC14","VWC15",
"VWC16","VWC17","VWC18") # these are arbitrary numbers, need to rename
# extract the data and give it useful col names
vwchourlyDepth <- CR1000_DepthTM[vwcrows, vwccols]
names(vwchourlyDepth) <- vwcnamesDepth
# replace 7999 values with NA
vwchourlyDepth[vwchourlyDepth==7999] <- NA
## because the datalogger uses 7999 for NA data
# make separate columns for date and time
vwchourlyDepth$TIMESTAMP2 <- parse_date_time(vwchourlyDepth$TIMESTAMP, orders="mdy HM") # as date
# get hour
vwchourlyDepth$Hour <- gsub( ".* ", "", vwchourlyDepth$TIMESTAMP) # as character
vwchourlyDepth$Hour2 <- hour(vwchourlyDepth$TIMESTAMP2) # as int
# get date
vwchourlyDepth$Date <- gsub( " .*$", "", vwchourlyDepth$TIMESTAMP) # as character
vwchourlyDepth$Date2 <- mdy(vwchourlyDepth$Date) # as date
## convert to long format
vwchourlylong <- gather(vwchourlyDepth, SensorID, VWC, VWC1:VWC18)
vwchourlylong$SensorID <- as.character(vwchourlylong$SensorID)
vwchourlylong$VWC <- as.numeric(vwchourlylong$VWC)
## add real sensor IDs
VWCIDs <- read.csv(paste(calibrationdatapath,"VWCIDmatching.csv",
sep=""), stringsAsFactors=FALSE)
vwchourlylongcor <- full_join(vwchourlylong,VWCIDs)
## get daily mean, sd, max, min
vwcdailylong <- ddply(vwchourlylongcor,.(Date2, SensorID,
RealID, TopoLocation,Depth),
summarize,
avgVWC=mean(VWC, na.rm = TRUE),
sdVWC=sd(VWC, na.rm = TRUE),
seVWC=ste(VWC),
maxVWC=max(VWC, na.rm = TRUE),
minVWC=min(VWC, na.rm = TRUE)) # na.rm=T already in the function definition for ste()
## get Depth data
# where is the temp data?
tempcols <- c(1,5,11,17,23,29,35,41,47,53,59,65,71,77,83) #no temp data from C616?
#vwccols  <- c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33)
dataend <- dim(CR1000_DepthTM)[1]
temprows <- c(4:dataend)
# what are the variable names?
tempnamesDepth <- c("TIMESTAMP","VWC1","VWC2","VWC3","VWC4","VWC5",
"VWC6","VWC7","VWC8","VWC9","VWC10",
"VWC11","VWC12","VWC13","VWC14") #again arbitrary but should match the VWC data
# extract the data and give it useful col names
temphourlyDepth <- CR1000_DepthTM[temprows, tempcols]
names(temphourlyDepth) <- tempnamesDepth
# replace 7999 values with NA
temphourlyDepth[temphourlyDepth==7999] <- NA
# make separate columns for date and time
temphourlyDepth$TIMESTAMP2 <- parse_date_time(temphourlyDepth$TIMESTAMP, orders="mdy HM") # as date
# get hour
temphourlyDepth$Hour <- gsub( ".* ", "", temphourlyDepth$TIMESTAMP) # as character
temphourlyDepth$Hour2 <- hour(temphourlyDepth$TIMESTAMP2) # as int
# get date
temphourlyDepth$Date <- gsub( " .*$", "", temphourlyDepth$TIMESTAMP) # as character
temphourlyDepth$Date2 <- mdy(temphourlyDepth$Date) # as date
## convert to long format
temphourlylong <- gather(temphourlyDepth, SensorID, Temp, VWC1:VWC14)
temphourlylong$SensorID <- as.character(temphourlylong$SensorID)
temphourlylong$Temp <- as.numeric(temphourlylong$Temp)
# add real IDs
temphourlylongcor <- full_join(temphourlylong,VWCIDs)
## get daily mean, sd, max, min
tempdailylong <- ddply(temphourlylongcor,.(Date2, SensorID,
RealID, TopoLocation,Depth),
summarize,
avgTemp=mean(Temp, na.rm = TRUE),
sdTemp=sd(Temp, na.rm = TRUE),
seTemp=ste(Temp),
smaxTemp=max(Temp, na.rm = TRUE),
minTemp=min(Temp, na.rm = TRUE)) # na.rm=T already in the function definition for ste()
# where is the O2 data?
O2cols <- c(1,331:345)
dataend <- dim(CR1000_oxygenEV)[1]
O2rows <- c(4:dataend)
# what are the variable names?
O2names <- c("TIMESTAMP",
"Ox01","Ox02","Ox03","Ox04","Ox05","Ox06",
"Ox07","Ox08","Ox09","Ox10","Ox11","Ox12",
"Ox13","Ox14","Ox15")
# extract the data and give it useful col names
O2hourly <- CR1000_oxygenEV[O2rows, O2cols]
names(O2hourly) <- O2names
## make useful columns
# replace 7999 values with NA
O2hourly[O2hourly==7999] <- NA
# make separate columns for date and time
O2hourly$TIMESTAMP2 <- parse_date_time(O2hourly$TIMESTAMP, orders="mdy HM") # as date
# get hour
O2hourly$Hour <- gsub( ".* ", "", O2hourly$TIMESTAMP) # as character
O2hourly$Hour2 <- hour(O2hourly$TIMESTAMP2) # as int
# get date
O2hourly$Date <- gsub( " .*$", "", O2hourly$TIMESTAMP) # as character
O2hourly$Date2 <- mdy(O2hourly$Date) # as date
## convert to long format
O2hourlylong <- gather(O2hourly, SensorID, O2mV, Ox01:Ox15)
O2hourlylong$SensorID <- as.character(O2hourlylong$SensorID)
O2hourlylong$O2mV <- as.numeric(O2hourlylong$O2mV)
## convert from mV to percent using the calibration curves for each sensor
# bring in calibration curve info
O2cal <- read.csv(paste(calibrationdatapath,"O2sensorscalibrationdepth.csv",sep=""), stringsAsFactors=FALSE) #using average of all calibration data
# join to O2hourlylong
O2hourlylong <- full_join(O2hourlylong, O2cal)
# solve for percent O2
O2hourlylong$O2pct <- ((O2hourlylong$O2mV * O2hourlylong$Slope) - O2hourlylong$Intercept) * 100
## add real sensor IDs
OxIDs <- read.csv(paste(calibrationdatapath,"OxIDmatching.csv",
sep=""), stringsAsFactors=FALSE)
O2hourlylongcor <- full_join(O2hourlylong,OxIDs)
## get daily mean, sd, max, min
O2dailylong <- ddply(O2hourlylongcor,.(Date2, SensorID,
RealID, TopoLocation,Depth),
summarize,
avgO2pct=mean(O2pct, na.rm = TRUE),
sdO2pct=sd(O2pct, na.rm = TRUE),
seO2pct=ste(O2pct),
smaxO2pct=max(O2pct, na.rm = TRUE),
minO2pct=min(O2pct, na.rm = TRUE)) # na.rm=T already in the function definition for ste()
########################################################################
# VWC + TEMP + O2 --> ONE DF
# add O2 dataframe into this once you've defined it
fulldaily1 <- full_join(tempdailylong, vwcdailylong,
by=c("Date2","RealID","SensorID","TopoLocation","Depth"))
fulldaily <- full_join(fulldaily1, O2dailylong, by=c("Date2","RealID","TopoLocation","Depth")) #when adding transect # etc this was called fulldaily2
#### modify this to ID sensors by depth and position later?
# put transect info in as a column near the front for easy reading
#definetransects <- read.csv(paste(calibrationdatapath,"definetransects.csv",sep=""), stringsAsFactors=FALSE)
#fulldaily3 <- full_join(fulldaily2, definetransects)
# dim(fulldaily3)[2] is where TransectID is; move to early column
#endcol <- dim(fulldaily3)[2]
#secondlast <- endcol-1
#fulldaily <- fulldaily3[,c(1:2,endcol,3:secondlast)]
# add TopoLocation
#defineTopoLocation <- read.csv(paste(calibrationdatapath,"defineTopoLocation.csv",sep=""), stringsAsFactors=FALSE)
#fulldaily4 <- full_join(fulldaily, defineTopoLocation)
# dim(fulldaily4)[2] is where TopoLocation is; move to early column
#endcol <- dim(fulldaily4)[2]
#secondlast <- endcol-1
#fulldaily <- fulldaily4[,c(1:2,endcol,3:secondlast)]
#fulldaily$TopoLocation <- as.factor(fulldaily$TopoLocation)
########################################################################
# DEFINE WHAT GETS ADDED TO THE RUNNING SPREADSHEET
# hourly wide for each
head(vwchourlyDepth)
head(temphourlyDepth)
head(O2hourly)
# daily wide for each
# go from long to wide using spread() from tidyr
# only do this for the average daily values, not the sd, se, min or max
vwcdailylongavg <- vwcdailylong[,c(1,3,6)]
vwcdailywideavg <- spread(vwcdailylongavg, RealID, avgVWC)
tempdailylongavg <- tempdailylong[,c(1,3,6)]
tempdailywideavg <- spread(tempdailylongavg, RealID, avgTemp)
O2dailylongavg <- O2dailylong[,c(1,3,6)]
O2dailywideavg <- spread(O2dailylongavg, RealID, avgO2pct)
head(tempdailywideavg)
head(vwcdailywideavg)
head(O2dailywideavg)
# daily long combined dataset
head(fulldaily)
########################################################################
# SAVE AS CSVS
# hourly wide for each
# make ok to write to CSV
vwchourlyDepth$TIMESTAMP2 <- as.character(vwchourlyDepth$TIMESTAMP2)
vwchourlyDepth$Date2 <- as.character(vwchourlyDepth$Date2)
temphourlyDepth$TIMESTAMP2 <- as.character(temphourlyDepth$TIMESTAMP2)
temphourlyDepth$Date2 <- as.character(temphourlyDepth$Date2)
O2hourlylong$TIMESTAMP2 <- as.character(O2hourlylong$TIMESTAMP2)
O2hourlylong$Date2 <- as.character(O2hourlylong$Date2)
# write to csv
write.csv(vwchourlyDepth, file=paste(outputdatapath, "vwchourly.csv", sep = ""), row.names=FALSE)
write.csv(temphourlyDepth, file=paste(outputdatapath, "temphourly.csv", sep = ""), row.names=FALSE)
write.csv(O2hourlylong, file=paste(outputdatapath, "O2hourly.csv", sep = ""), row.names=FALSE)
# daily wide for each
# make ok to write to CSV
vwcdailywideavg$Date2 <- as.character(vwcdailywideavg$Date2)
tempdailywideavg$Date2 <- as.character(tempdailywideavg$Date2)
O2dailywideavg$Date2 <- as.character(O2dailywideavg$Date2)
# write to csv
write.csv(vwcdailywideavg, file=paste(outputdatapath, "vwcdailywideavg.csv", sep = ""), row.names=FALSE)
write.csv(tempdailywideavg, file=paste(outputdatapath, "tempdailywideavg.csv", sep = ""), row.names=FALSE)
write.csv(O2dailywideavg, file=paste(outputdatapath, "O2dailywideavg.csv", sep = ""), row.names=FALSE)
# daily long combined dataset
# make ok to write to CSV
fulldaily$Date2 <- as.character(fulldaily$Date2)
# write to csv
write.csv(fulldaily, file=paste(outputdatapath, "fulldaily.csv", sep = ""), row.names=FALSE)
# make basic graphs
figuredata <- fulldaily[!is.na(fulldaily$TopoLocation),]
ggplot(figuredata,aes(x=as.Date(Date2),y=avgO2pct,color=factor(Depth))) +
geom_point() +
scale_x_date(limits=as.Date(c("2017-01-01","2017-07-01"))) +
labs(x="Date",y="O2 concentration") +
facet_grid(TopoLocation~.)
ggsave("DepthO2.jpg",path=outputdatapath)
ggplot(figuredata,aes(x=as.Date(Date2),y=avgTemp,color=factor(Depth))) +
geom_point() +
scale_x_date(limits=as.Date(c("2017-01-01","2017-07-01"))) +
labs(x="Date",y="Soil Temp") +
facet_grid(TopoLocation~.)
ggsave("DepthTemp.jpg",path=outputdatapath)
ggplot(figuredata,aes(x=as.Date(Date2),y=avgVWC,color=factor(Depth))) +
geom_point() +
scale_x_date(limits=as.Date(c("2017-01-01","2017-07-01"))) +
labs(x="Date",y="Volumetric Water Content") +
facet_grid(TopoLocation~.)
ggsave("DepthVWC.jpg",path=outputdatapath)
# Combine-depth-sensor-data
# based on "Process-depthsensorsdf-Sensor-Data-RCode"
#     (run that file on new data downloads first to create inputs!)
#
# Combines data from most recent download date ("NewDatapath")
#  with old array data ("DataArchivepath")
#  and saves complete dataset in the DataArchive
#  for seven files:
#                   fulldaily.csv
#                   O2dailywideavg.csv
#                   O2hourly.csv
#                   tempdailywideavg.csv
#                   temphourly.csv
#                   vwcdailywideavg.csv
#                   vwchourly.csv
######################################################################
# load packages
library(plyr)
library(dplyr)
# locate datasets
DataArchivepath <- "~/Desktop/Datalogger_downloads/DepthDataArchive/"
# old data; this should never change unless changing computers
# christine version; uncomment when CSO doing things
#DataArchivepath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceDataArchive/"
NewDatapath      <- "~/Desktop/Datalogger_downloads/4-12-17/Depth results/"
# this should change each time data is dowloaded
# christine version; uncomment when CSO doing things
#NewDatapath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceNewest/"
# when christine was adding in the very old data
#NewDatapath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceOutOfDate/OldestCSOHas/renamedtomatchcode/"
# create master list of file names
allfiles <- c("fulldaily","O2dailywideavg","O2hourly",
"tempdailywideavg","temphourly",
"vwcdailywideavg","vwchourly")
# bring in old data
OldFiles <- list()
for(i in 1:7) {
OldFiles[[i]] <- as.data.frame(read.csv(paste(DataArchivepath,allfiles[i],".csv",sep=""), stringsAsFactors=FALSE))
names(OldFiles)[i] <- paste("Old",allfiles[i],sep="")
}
# bring in new data
NewFiles <- list()
for(i in 1:7) {
NewFiles[[i]] <- as.data.frame(read.csv(paste(NewDatapath,allfiles[i],".csv",sep=""), stringsAsFactors=FALSE))
names(NewFiles)[i] <- paste("New",allfiles[i],sep="")
}
# Bind datasets
CompleteFiles <- list()
for(i in 1:7) {
stopifnot(names(OldFiles[[i]])==names(NewFiles[[i]]))
CompleteFiles[[i]] <- join(OldFiles[[i]],NewFiles[[i]],type="full")
names(CompleteFiles)[i] <- paste("Complete",allfiles[i],sep="")
}
# Save all data
for(i in 1:7){
write.csv(CompleteFiles[[i]],
file=paste(DataArchivepath,allfiles[i],".csv",sep=""),
row.names=FALSE)
}
# Figures for sanity check
library(ggplot2)
library(lubridate)
fulldaily <- CompleteFiles[[1]]
fulldaily$realDate <- parse_date_time(fulldaily$Date2,orders="mdy")
ggplot(fulldaily,aes(x=realDate,y=avgO2pct,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
scale_y_continuous(limits=c(-2,22)) +
labs(x="Date",y="O2 concentration")
ggsave("Depth O2.pdf", path = DataArchivepath)
ggplot(fulldaily,aes(x=realDate,y=avgTemp,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="Soil Temp")
ggsave("Depth Soil Temp.pdf", path = DataArchivepath)
ggplot(fulldaily,aes(x=realDate,y=avgVWC,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="Volumetric Water Content")
ggsave("Depth VWC.pdf", path = DataArchivepath)
str(fulldaily)
View(fulldaily)
str(oldFiles[[i]])
str(OldFiles[[i]])
str(NewFiles[[i]])
str(OldFiles[[1]])
str(NewFiles[[1]])
test <- mdy(OldFiles[[1]]$Date2)
View(test)
lenght(OldFiles[[1]]$Date2)
length(OldFiles[[1]]$Date2)
test <- OldFiles[[1]]$Date2
str(test)
View(test)
View(test)
test
tail(test)
test[1000:2000]
test[2000:3000]
test[3000:4000]
test[4000:5000]
test[5000:6000]
test2 <- test[1:5495]
test3 <- test[5495:]
test3 <- test[5495:length(test)]
test2 <- mdy(test2)
test2 <- test[1:5494]
test2 <- mdy(test2)
test3 <- ymd(test3)
fintest <- rbind(test2,test3)
str(test2)
str(test3)
str(fintest)
fintest <- c(test2,test3)
str(fintest)
OldFiles[[1]]$Date2 <- as.character(fintest)
# Bind datasets
CompleteFiles <- list()
for(i in 1:7) {
stopifnot(names(OldFiles[[i]])==names(NewFiles[[i]]))
CompleteFiles[[i]] <- join(OldFiles[[i]],NewFiles[[i]],type="full")
names(CompleteFiles)[i] <- paste("Complete",allfiles[i],sep="")
}
library(ggplot2)
library(lubridate)
fulldaily <- CompleteFiles[[1]]
fulldaily$realDate <- parse_date_time(fulldaily$Date2,orders="mdy")
ggplot(fulldaily,aes(x=realDate,y=avgO2pct,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
scale_y_continuous(limits=c(-2,22)) +
labs(x="Date",y="O2 concentration")
ggsave("Depth O2.pdf", path = DataArchivepath)
ggplot(fulldaily,aes(x=realDate,y=avgTemp,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="Soil Temp")
ggsave("Depth Soil Temp.pdf", path = DataArchivepath)
ggplot(fulldaily,aes(x=realDate,y=avgVWC,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="Volumetric Water Content")
ggsave("Depth VWC.pdf", path = DataArchivepath)
str(fulldaily)
library(ggplot2)
library(lubridate)
fulldaily <- CompleteFiles[[1]]
fulldaily$realDate <- parse_date_time(fulldaily$Date2,orders="ymd")
ggplot(fulldaily,aes(x=realDate,y=avgO2pct,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
scale_y_continuous(limits=c(-2,22)) +
labs(x="Date",y="O2 concentration")
ggsave("Depth O2.pdf", path = DataArchivepath)
ggplot(fulldaily,aes(x=realDate,y=avgTemp,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="Soil Temp")
ggsave("Depth Soil Temp.pdf", path = DataArchivepath)
ggplot(fulldaily,aes(x=realDate,y=avgVWC,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="Volumetric Water Content")
ggsave("Depth VWC.pdf", path = DataArchivepath)
ggplot(fulldaily,aes(x=realDate,y=avgO2pct,color=as.factor(Depth))) +
geom_point() +
facet_grid(TopoLocation~.) +
labs(x="Date",y="O2 concentration")
ggsave("Depth O2.pdf", path = DataArchivepath)
#  scale_y_continuous(limits=c(-2,22)) +
View(subset(fulldaily,as.factor(fulldaily$Depth)==75) & fulldaily$TopoLocation=="Valley")
?and
View(subset(fulldaily,as.factor(fulldaily$Depth)==75))
for(i in 1:7){
write.csv(CompleteFiles[[i]],
file=paste(DataArchivepath,allfiles[i],".csv",sep=""),
row.names=FALSE)
}
# Combine-array-sensor-data
# based on "Process-arraysensorsdf-Sensor-Data-RCode"
#     (run that file on new data downloads first to create inputs!)
#
# Combines data from most recent download date ("NewDatapath")
#  with old array data ("DataArchivepath")
#  and saves complete dataset in the DataArchive
#  for seven files:
#                   fulldaily.csv
#                   O2dailywideavg.csv
#                   O2hourly.csv
#                   tempdailywideavg.csv
#                   temphourly.csv
#                   vwcdailywideavg.csv
#                   vwchourly.csv
######################################################################
# load packages
library(plyr)
library(dplyr)
# locate datasets
DataArchivepath <- "~/Desktop/Datalogger_downloads/DataArchive/"
# old data; this should never change unless changing computers
# christine version; uncomment when CSO doing things
#DataArchivepath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceDataArchive/"
NewDatapath      <- "~/Desktop/Datalogger_downloads/4-12-17/Surface results/"
# this should change each time data is dowloaded
# christine version; uncomment when CSO doing things
#NewDatapath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceNewest/"
# when christine was adding in the very old data
#NewDatapath <- "~/Documents/GITHUB/cso044code_HotSpotsHotMoments/HotSpotsHotMomentsAnalysis/HotSpotsHotMoments-Data-Raw/Sensors/SurfaceOutOfDate/OldestCSOHas/renamedtomatchcode/"
# create master list of file names
allfiles <- c("vwchourly","temphourly","O2hourly","fulldaily",
"O2dailywideavg", "tempdailywideavg","vwcdailywideavg")
# bring in old data
OldFiles <- list()
for(i in 1:7) {
OldFiles[[i]] <- as.data.frame(read.csv(paste(DataArchivepath,allfiles[i],".csv",sep=""), stringsAsFactors=FALSE))
names(OldFiles)[i] <- paste("Old",allfiles[i],sep="")
}
